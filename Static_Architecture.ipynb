{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msNrqClZYSZM"
      },
      "source": [
        "# Static Architecture of a System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEauQvzZUKCU"
      },
      "source": [
        "### Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABHy8se7UMZM",
        "outputId": "bcac5153-35fa-4f85-ec9a-82e74585e625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.0.17)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.7.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install -U spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "581MWXStf-sx",
        "outputId": "fabf16c2-4598-4852-f546-a616b10b24ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting plantuml\n",
            "  Downloading plantuml-0.3.0-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.7/dist-packages (from plantuml) (0.17.4)\n",
            "Installing collected packages: plantuml\n",
            "Successfully installed plantuml-0.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install plantuml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLi2tjj3UEUr"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WXC1fh4sT0RF"
      },
      "outputs": [],
      "source": [
        "# Spacy Imports\n",
        "import spacy \n",
        "from spacy.lang.en import English\n",
        "\n",
        "# TextBlob Imports \n",
        "from textblob import TextBlob\n",
        "\n",
        "# nltk Imports \n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "#plantUML Imports \n",
        "import plantuml\n",
        "from plantuml import PlantUML\n",
        "\n",
        "# Other Imports \n",
        "import string\n",
        "from os.path import abspath \n",
        "import collections\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKx1IxK_Uhmq"
      },
      "source": [
        "### nltk downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cqj1Uf2UQ_l",
        "outputId": "8b1f3812-0fa8-4296-c316-7df87086d952"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CVua2WeZCv3"
      },
      "source": [
        "### PlantUML Code Generator "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenAndPOS_Tags(sent): \n",
        "  nlp = English()\n",
        "  token_sentence = nlp(sent)\n",
        "  # Allows the tokenizing of special words, this way words containing all \n",
        "  # symbols outside of the ones outlined are not seperated\n",
        "  # Eg: Inhibited_count>=2\n",
        "  suffixes = nlp.Defaults.suffixes + [r\"\\-|\\|\\$\",]\n",
        "  suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
        "  nlp.tokenizer.suffix_search = suffix_regex.search\n",
        "\n",
        "  doc = nlp(sent)\n",
        "  token_sentence = []\n",
        "  # Extract the token and store them in the token_sentence list\n",
        "  for token in doc:\n",
        "    token_sentence.append(token.text)\n",
        "\n",
        "  # POS Tag the tokens \n",
        "  pos_tag_token = nltk.pos_tag(token_sentence)\n",
        "  \n",
        "  return token_sentence, pos_tag_token"
      ],
      "metadata": {
        "id": "8GXbPbTCv_Zs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Noun Extraction functions \n",
        "def nounExtraction(tag_tokens):\n",
        "  # Noun Extraction (only extracting Proper Nouns)\n",
        "  nltk_nouns = []\n",
        "  for index,tuple in enumerate(tag_tokens):\n",
        "    if tuple[1] == 'NNP':\n",
        "      nltk_nouns.append(tuple[0])\n",
        "  return nltk_nouns"
      ],
      "metadata": {
        "id": "iUwE9K39Hg4q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of Synonyms for consist and connect\n",
        "# This is used oppose the stemming as certain Proper Nouns where being truncated \n",
        "def synonyms_lists(): \n",
        "  consist_synonyms = ['consist', 'consists','include','includes', 'comprise', 'comprises']\n",
        "  connect_synonyms = ['connection','connections', 'connects', 'connect']\n",
        "  input_synonyms = ['input', 'accepts', 'accept']\n",
        "\n",
        "  return consist_synonyms, connect_synonyms, input_synonyms"
      ],
      "metadata": {
        "id": "Iroq0kVQwcgi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Editing or creating text file if it doesn't exists\n",
        "# Creating the code for plantuml to generate a component based diagram\n",
        "\n",
        "def staticPlantumlCode(text): \n",
        "  # Used to tokenize a sentence \n",
        "  doc = sent_tokenize(text)\n",
        "  main_sub_component = []\n",
        "\n",
        "  f = open('model_specs.txt','w')    \n",
        "  # Iterate sentence-by-sentence then word-by-word \n",
        "  for sent in doc:\n",
        "    # Call Tokenize and Stemming and POS Tag Function\n",
        "    token_sentence, pos_tag_token = tokenAndPOS_Tags(sent)\n",
        "            \n",
        "    # Call Noun Extraction Function \n",
        "    # First noun is the main noun, the other nouns are its associations(inputs,\n",
        "    # sub-components and outputs)\n",
        "    nltk_nouns = nounExtraction(pos_tag_token)    \n",
        "    \n",
        "    # Used to increment the number of elements in the list of nouns\n",
        "    i = 1\n",
        "  \n",
        "    # Call synonyms \n",
        "    consist_synonyms, connect_synonyms, input_synonyms = synonyms_lists()\n",
        "\n",
        "    # create sets variable to check if consist synonyms are being used \n",
        "    t_sentence_set = set(token_sentence)\n",
        "    consist_set = set(consist_synonyms)\n",
        "    connect_set = set(connect_synonyms)\n",
        "    input_set = set(input_synonyms)\n",
        "    # If any synonym to consist exsists in the token list\n",
        "    if (consist_set & t_sentence_set): \n",
        "      while(i < len(nltk_nouns)): \n",
        "        main_sub_component = nltk_nouns[1:]\n",
        "        i = i + 1 \n",
        "    \n",
        "    # If any synonym to connect exsists in the token list\n",
        "    if (connect_set & t_sentence_set):\n",
        "      while(i < len(nltk_nouns)): \n",
        "          # Find the index of the first noun extracted in the main_sub_component\n",
        "          # to prioritize order\n",
        "          if(main_sub_component.index(nltk_nouns[0]) > \n",
        "             main_sub_component.index(nltk_nouns[i])):\n",
        "            f.write(f\"[{nltk_nouns[i]}]-[{nltk_nouns[0]}]\\n\")\n",
        "          else: \n",
        "            f.write(f\"[{nltk_nouns[0]}]-[{nltk_nouns[i]}]\\n\")             \n",
        "          i = i+1\n",
        "\n",
        "    # If any synonyms to input is in the token \n",
        "    if(input_set & t_sentence_set):\n",
        "      # If input and clock is in the token \n",
        "      if \"clock\" in token_sentence: \n",
        "        while(i < len(nltk_nouns)): \n",
        "          f.write(f\"{nltk_nouns[0]}<-up-({nltk_nouns[i]})\\n\")\n",
        "          i = i+1\n",
        "      # If input and boolean is in the token \n",
        "      elif \"boolean\" in token_sentence: \n",
        "        while(i < len(nltk_nouns)):    \n",
        "            f.write(f\"({nltk_nouns[i]}: boolean)->[{nltk_nouns[0]}]\\n\")\n",
        "            i = i+1\n",
        "      else: \n",
        "        while(i < len(nltk_nouns)):\n",
        "          f.write(f\"({nltk_nouns[i]})->[{nltk_nouns[0]}]\\n\")\n",
        "          i = i+1\n",
        "    # If output is in the token       \n",
        "    if \"output\" in token_sentence: \n",
        "      while(i < len(nltk_nouns)): \n",
        "          f.write(f\"{nltk_nouns[0]}->({nltk_nouns[i]})\\n\")\n",
        "          i = i+1\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "oq6BnIkNSlVh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FGS System Example\n",
        "Static Architecture"
      ],
      "metadata": {
        "id": "07wmSWhKv2HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specification text\n",
        "text = (\" 1.\tThe FGS_System consists of four components: the Left_Side_FGS, an LR_Bus, and an RL_Bus, the Right_Side_FGS.\"\n",
        "        \" 2.\tLR_Bus establishes connection between Left_Side_FGS and Right_Side_FGS.\"\n",
        "        \" 3.\tThe LR_Bus takes input from clock CLK2.\"\n",
        "        \" 4.\tRL_Bus establishes connection between Left_Side_FGS and Right_Side_FGS.\"\n",
        "        \" 5.\tThe RL_Bus takes input from clock CLK4.\"\n",
        "        \" 6.\tThe Left_Side_FGS accepts as input a boolean value of Left_Transfer_Switch and Left_Primary_Side.\"\n",
        "        \" 8.\tThe Left_Side_FGS takes input from a synchronous clock CLK1.\"\n",
        "        \" 7.\tThe Right_Side_FGS accepts as input a boolean value of Right_Transfer_Switch and Right_Primary_Side.\"\n",
        "        \" 9.\tThe Right_Side_FGS takes input from a synchronous clock CLK3.\")\n"
      ],
      "metadata": {
        "id": "9QcWTEchamGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2zZT7TRdJDT",
        "outputId": "9e8a1a94-5749-45df-e968-ccbd72e4daa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' 1.',\n",
              " 'The Active_Standby_System consists of four components: Side_1, Bus_12, Bus_21, and  Side_2.',\n",
              " '2.',\n",
              " 'Bus_12 connects Side_1 with Side_2.',\n",
              " '3.',\n",
              " 'Bus_12 takes input from clock CLK_12.',\n",
              " '4.',\n",
              " 'Bus_12 takes input from Side_1_Status.',\n",
              " '5.',\n",
              " 'Bus_21 connects Side_2 with Side_1.',\n",
              " '6.',\n",
              " 'Bus_21 takes input from clock CLK_21.',\n",
              " '7.',\n",
              " 'Side_1 accepts Manual_Selection, Side_1SubSystem_Status, and Side2SubSystem_Status as input.',\n",
              " '8.',\n",
              " 'Side_1 accepts a input boolean value Side_1_Failed and Primary_Side as input.',\n",
              " '9.',\n",
              " 'Side_1 takes input from clock CLK_1.',\n",
              " '10.',\n",
              " 'Side_1 input signal is the Side_2_Status.',\n",
              " '11.',\n",
              " 'Side_1 generates Side_1_Status as an output.',\n",
              " '13.',\n",
              " 'Side_2 accepts Manual_Selection, Side_1SubSystem_Status, and Side2SubSystem_Status as input.',\n",
              " '14.',\n",
              " 'Side_2 accepts a input boolean value, Side_2_Failed and Primary_Side as input.',\n",
              " '15.',\n",
              " 'Side_2 takes Side_1_Status as input.',\n",
              " '16.',\n",
              " 'Side_2 takes input from clock CLK_2.',\n",
              " '17.',\n",
              " 'Side_2 generates Side_2_Status as an output.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGAHEhspolLv"
      },
      "source": [
        "Creating System Diagram using PlantUML Code Generator for FGS Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOGDCvPyifYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a42f793c-a775-44f8-a9b1-464ac41a8b72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "staticPlantumlCode(text)\n",
        "server = PlantUML(url='http://www.plantuml.com/plantuml/img/',\n",
        "                          basic_auth={},\n",
        "                          form_auth={}, http_opts={}, request_opts={})\n",
        "\n",
        "server.processes_file(abspath('model_specs.txt'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiCe1luNjwN0"
      },
      "source": [
        "### Active Standby System Example\n",
        "Static Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gocdhmLzYbLM"
      },
      "outputs": [],
      "source": [
        "text = (\" 1.\tThe Active_Standby_System consists of four components: Side_1, Bus_12, Bus_21, and  Side_2.\"\n",
        "        \" 2.\tBus_12 connects Side_1 with Side_2.\"\n",
        "        \" 3.\tBus_12 takes input from clock CLK_12.\"\n",
        "        \" 4.\tBus_12 takes input from Side_1_Status.\"\n",
        "        \" 5.\tBus_21 connects Side_2 with Side_1.\"\n",
        "        \" 6.\tBus_21 takes input from clock CLK_21.\"\n",
        "        \" 7.\tSide_1 accepts Manual_Selection, Side_1SubSystem_Status, and Side2SubSystem_Status as input.\" \n",
        "        \" 8.\tSide_1 accepts a input boolean value Side_1_Failed and Primary_Side as input.\"\n",
        "        \" 9.\tSide_1 takes input from clock CLK_1.\"\n",
        "        \" 10.\tSide_1 input signal is the Side_2_Status.\"\n",
        "        \" 11.\tSide_1 generates Side_1_Status as an output.\"\n",
        "        \" 13.\tSide_2 accepts Manual_Selection, Side_1SubSystem_Status, and Side2SubSystem_Status as input.\"\n",
        "        \" 14.\tSide_2 accepts a input boolean value, Side_2_Failed and Primary_Side as input.\"\n",
        "        \" 15.\tSide_2 takes Side_1_Status as input.\"\n",
        "        \" 16.\tSide_2 takes input from clock CLK_2.\"\n",
        "        \" 17.\tSide_2 generates Side_2_Status as an output.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BYuel4TEZ8WW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47b9d07-e3c5-4197-a6d6-5fdddb45cacc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' 1.',\n",
              " 'The Active_Standby_System consists of four components: Side_1, Bus_12, Bus_21, and  Side_2.',\n",
              " '2.',\n",
              " 'Bus_12 connects Side_1 with Side_2.',\n",
              " '3.',\n",
              " 'Bus_12 takes input from clock CLK_12.',\n",
              " '4.',\n",
              " 'Bus_12 takes input from Side_1_Status.',\n",
              " '5.',\n",
              " 'Bus_21 connects Side_2 with Side_1.',\n",
              " '6.',\n",
              " 'Bus_21 takes input from clock CLK_21.',\n",
              " '7.',\n",
              " 'Side_1 accepts Manual_Selection, Side_1SubSystem_Status, and Side2SubSystem_Status as input.',\n",
              " '8.',\n",
              " 'Side_1 accepts a input boolean value Side_1_Failed and Primary_Side as input.',\n",
              " '9.',\n",
              " 'Side_1 takes input from clock CLK_1.',\n",
              " '10.',\n",
              " 'Side_1 input signal is the Side_2_Status.',\n",
              " '11.',\n",
              " 'Side_1 generates Side_1_Status as an output.',\n",
              " '13.',\n",
              " 'Side_2 accepts Manual_Selection, Side_1SubSystem_Status, and Side2SubSystem_Status as input.',\n",
              " '14.',\n",
              " 'Side_2 accepts a input boolean value, Side_2_Failed and Primary_Side as input.',\n",
              " '15.',\n",
              " 'Side_2 takes Side_1_Status as input.',\n",
              " '16.',\n",
              " 'Side_2 takes input from clock CLK_2.',\n",
              " '17.',\n",
              " 'Side_2 generates Side_2_Status as an output.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TZWwxW-S-nv"
      },
      "source": [
        "Creating System Diagram using PlantUML Code Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7u5rrtPtYbRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982ed0b2-14f8-48df-b3d8-d061a8726631"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "staticPlantumlCode(text)\n",
        "server = PlantUML(url='http://www.plantuml.com/plantuml/img/',\n",
        "                          basic_auth={},\n",
        "                          form_auth={}, http_opts={}, request_opts={})\n",
        "\n",
        "server.processes_file(abspath('model_specs.txt'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bEauQvzZUKCU",
        "pLi2tjj3UEUr",
        "WKx1IxK_Uhmq",
        "eCn7rPwKUok4",
        "CGAHEhspolLv",
        "IiCe1luNjwN0"
      ],
      "name": "Static Architecture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}